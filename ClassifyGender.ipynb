{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender classification task on human face images using Naive Bayes and logistic regression classifier. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Problem Statement](#section1)<br>\n",
    "1. Download a dataset from https://github.com/StephenMilborrow/muct . Group the images into male and female categories based on the images. \n",
    "2. Randomly sample the face images to create a male and female face training sets consisting of 70% of the face images. Rest 30% face images form the face testing images. \n",
    "3. Build Naive Bayes classifier for male and female faces. Use intensity and SVD based features for these classifiers. \n",
    "4. Build a logistic regression based classifier for male and female faces. Use intensity and SVD based features for these classifiers. \n",
    "5. Calculate accuracy for the training set and testing set for the above classifiers, for both intensity and SVD based features and confusion matrix. \n",
    "6. Compare the performance of the above classifiers and report your observations. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing necessary packages\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import face_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group the images into male and female categories based on the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# getting the path:\n",
    "basePath= os.path.dirname(os.getcwd())\n",
    "imagesPath = basePath+\"/faces/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# defining empty list to hold rawImages , features and corresponding labels\n",
    "rawImages = []\n",
    "features = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to convert image to feature vector by resizing the images and flattening the matrix \n",
    "\n",
    "def image_to_feature_vector(image, size=(100, 100)):\n",
    "    # resize the image to a fixed size, then flatten the image into\n",
    "    # a list of raw pixel intensities\n",
    "    return cv2.resize(image, size).flatten()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Our input image  will be shrunk to 100 x 100 pixels, \n",
    "and given three channels for each Red, Green, and Blue component respectively, \n",
    "our output “feature vector” will be a list of 100 x 100 x 3 = 3,00,00 numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import imutils\n",
    "def extract_color_histogram(image, bins=(8, 8, 8)):\n",
    "    # extract a 3D color histogram from the HSV color space using\n",
    "    # the supplied number of `bins` per channel\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv], [0, 1, 2], None, bins,\n",
    "        [0, 180, 0, 256, 0, 256])\n",
    "    \n",
    "    # handle normalizing the histogram if we are using OpenCV 2.4.X\n",
    "    if imutils.is_cv2():\n",
    "        hist = cv2.normalize(hist)\n",
    "    \n",
    "    # otherwise, perform \"in place\" normalization in OpenCV 3 (I\n",
    "    # personally hate the way this is done\n",
    "    else:\n",
    "        cv2.normalize(hist, hist)\n",
    "    \n",
    "    # return the flattened histogram as the feature vector\n",
    "    return hist.flatten()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The above function accepts an input image  and constructs a color histogram to characterize \n",
    "the color distribution of the image.\n",
    "\n",
    "First, we convert our image  to the HSV color space . \n",
    "We then apply the cv2.calcHist  function to compute a 3D color histogram for the image\n",
    "\n",
    "Given our computed hist , we then normalize it, taking care to use the appropriate cv2.normalize  function signature based on our OpenCV version  .\n",
    "\n",
    "Given 8 bins for each of the Hue, Saturation, and Value channels respectively, our final feature vector is of size 8 x 8 x 8 = 512, thus our image is characterized by a 512-d feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loop over the input images\n",
    "import re\n",
    "def prepare_all_data(imagesPath):\n",
    "    dirs = os.listdir(imagesPath)\n",
    "    for i in dirs:\n",
    "        # load the image and extract the class label (assuming that our\n",
    "        # path as the format: /path/to/dataset/{class}.{image_num}.jpg\n",
    "        image = cv2.imread(imagesPath+i)\n",
    "        extractLabel = (re.split(\"-\",i)[-1]).split(\".\",1)[0]\n",
    "        if(extractLabel.startswith('m')):\n",
    "            label=\"male\"\n",
    "        else:\n",
    "            label=\"female\"\n",
    "    \n",
    "        # extract raw pixel intensity \"features\", followed by a color\n",
    "        # histogram to characterize the color distribution of the pixels\n",
    "        # in the image\n",
    "        pixels = image_to_feature_vector(image)\n",
    "        hist = extract_color_histogram(image)\n",
    "    \n",
    "        # update the raw images, features, and labels matricies,\n",
    "        # respectively\n",
    "        rawImages.append(pixels)\n",
    "        features.append(hist)\n",
    "        labels.append(label)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Given our features labels, we then update the respective rawImages , features , and labels  lists \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prepare_all_data(imagesPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Holding Raw Images and features in array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] pixels matrix: 22.00MB\n",
      "[INFO] features matrix: 1.50MB\n"
     ]
    }
   ],
   "source": [
    "rawImages = np.array(rawImages)\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "print(\"[INFO] pixels matrix: {:.2f}MB\".format(\n",
    "    rawImages.nbytes / (1024 * 1000.0)))\n",
    "print(\"[INFO] features matrix: {:.2f}MB\".format(\n",
    "    features.nbytes / (1024 * 1000.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting Raw Images and feature Vectors in train test split\n",
    "\n",
    "#### Randomly sample the face images to create a male and female face training sets consisting of 75% of the face images. Rest 25% face images form the face testing images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(trainRI, testRI, trainRL, testRL) = train_test_split(\n",
    "    rawImages, labels, test_size=0.25, random_state=42)\n",
    "(trainFeat, testFeat, trainLabels, testLabels) = train_test_split(\n",
    "    features, labels, test_size=0.25, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In the above function the features have been split into Raw Images(Pixel Matrix) \n",
    "and Features Matrix(holding color intensity ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Naive Bayes classifier for male and female faces. Use intensity and SVD based features for these classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes using SVD on the Raw Images Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Using SVD to reduce the dimensions of the vectors \n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=511)\n",
    "svd.fit(trainRI)\n",
    "new_train=svd.transform(trainRI) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fit the transformed train images on the GaussianNB\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Create a Gaussian Classifier\n",
    "model_GNB = GaussianNB()\n",
    "model_GNB.fit(new_train,trainRL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform the Raw Images on the test using SVD\n",
    "new_test=svd.transform(testRI) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((188, 511), (188,))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get the shape of transformed test images and labels\n",
    "new_test.shape,testRL.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the accuracy of the scores on the raw Images features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Raw pixel accuracy: 72.34%\n"
     ]
    }
   ],
   "source": [
    "score=model_GNB.score(new_test,testRL)\n",
    "print(\"[INFO] Raw pixel accuracy: {:.2f}%\".format(score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictedRaw = model_GNB.predict(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw pixel Actual values Count:  188\n",
      "Raw pixel Predicted values:  136\n"
     ]
    }
   ],
   "source": [
    "predRawCnt=0\n",
    "for i in range(len(testRL)):\n",
    "    if(testRL[i]==predictedRaw[i]):\n",
    "        predRawCnt+=1\n",
    "print(\"Raw pixel Actual values Count: \",(len(testRL)))\n",
    "print(\"Raw pixel Predicted values: \",(predRawCnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### male and female count in Actual test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Male Count in test Data: 88\n",
      "Actual FeMale Count in test Data: 100\n"
     ]
    }
   ],
   "source": [
    "count_f=0\n",
    "count_m=0\n",
    "for i in range(len(testRL)):\n",
    "    if(testRL[i]=='male'):\n",
    "        count_m=count_m+1\n",
    "    else:\n",
    "        count_f=count_f+1\n",
    "print(\"Actual Male Count in test Data:\",count_m)\n",
    "print(\"Actual FeMale Count in test Data:\",count_f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix for the Naive bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[77 23]\n",
      " [29 59]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "labels = ['female', 'male']\n",
    "cm_logistic = metrics.confusion_matrix(testRL, predictedRaw)\n",
    "print(cm_logistic)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm_logistic)\n",
    "plt.title('Confusion matrix of the Naive classifier \\n')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes using SVD on the feature Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Using SVD to reduce the dimensions of the feature vectors  \n",
    "\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=511)\n",
    "svd.fit(trainFeat)\n",
    "new_train_feat=svd.transform(trainFeat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Fitting Naive bayes on the feature vectors using Gaussian Classifier\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Create a Gaussian Classifier\n",
    "model_GNB_feat = GaussianNB()\n",
    "model_GNB_feat.fit(new_train_feat,trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform the feature vectors  on the test using SVD\n",
    "new_test_feat=svd.transform(testFeat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Feature Matrix accuracy: 46.81%\n"
     ]
    }
   ],
   "source": [
    "score=model_GNB.score(new_test_feat,testLabels)\n",
    "print(\"[INFO] Feature Matrix accuracy: {:.2f}%\".format(score * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:: Since the feature matrix vector accuray is not good so we can discard the feature Matrix vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> Build a logistic regression based classifier for male and female faces. \n",
    "              \n",
    "              Use intensity and SVD based features for these classifiers!</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(new_train,trainRL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the accuracy of the scores on the raw Images features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Raw pixel accuracy: 90.43%\n"
     ]
    }
   ],
   "source": [
    "score=logisticRegr.score(new_test,testRL)\n",
    "print(\"[INFO] Raw pixel accuracy: {:.2f}%\".format(score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictedLogRaw = logisticRegr.predict(new_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### male and female count in Actual test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Male Count in test Data: 88\n",
      "Actual FeMale Count in test Data: 100\n"
     ]
    }
   ],
   "source": [
    "count_f=0\n",
    "count_m=0\n",
    "for i in range(len(testRL)):\n",
    "    if(testRL[i]=='male'):\n",
    "        count_m=count_m+1\n",
    "    else:\n",
    "        count_f=count_f+1\n",
    "print(\"Actual Male Count in test Data:\",count_m)\n",
    "print(\"Actual FeMale Count in test Data:\",count_f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix for the Logistic based classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[98  2]\n",
      " [16 72]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "labels = ['female', 'male']\n",
    "cm_logistic = metrics.confusion_matrix(testRL, predictedLogRaw)\n",
    "print(cm_logistic)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm_logistic)\n",
    "plt.title('Confusion matrix of the classifier \\n')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
