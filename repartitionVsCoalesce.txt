https://hackernoon.com/managing-spark-partitions-with-coalesce-and-repartition-4050c57ad5c4
scala> val x = (1 to 12).toList
x: List[Int] = List(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12)

scala> val numbersDf = x.toDF("number")
numbersDf: org.apache.spark.sql.DataFrame = [number: int]

scala> numbersDf.rdd.partitions.size 
res10: Int = 4
OR 
scala> numbersDf.rdd.partitions.length
res13: Int = 4
OR
scala> numbersDf.rdd.getNumPartitions
res14: Int = 4

scala> numbersDf.collect()
res16: Array[org.apache.spark.sql.Row] = Array([1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12])

now it has 4 partions 
scala> numbersDf.write.csv("/Users/p.kumar.bishwal/Documents/python/codeNdata/output/numbers")

here you can see the 4 files are created in the folder part-0000 to  part-0003
scala> spark.read.format("csv").load("/Users/p.kumar.bishwal/Documents/python/codeNdata/output/numbers/part-00000.csv").collect()
res21: Array[org.apache.spark.sql.Row] = Array([1], [2], [3])

scala> spark.read.format("csv").load("/Users/p.kumar.bishwal/Documents/python/codeNdata/output/numbers/part-00001.csv").collect()
res22: Array[org.apache.spark.sql.Row] = Array([4], [5], [6])

scala> spark.read.format("csv").load("/Users/p.kumar.bishwal/Documents/python/codeNdata/output/numbers/part-00002.csv").collect()
res23: Array[org.apache.spark.sql.Row] = Array([7], [8], [9])

scala> spark.read.format("csv").load("/Users/p.kumar.bishwal/Documents/python/codeNdata/output/numbers/part-00003.csv").collect()
res24: Array[org.apache.spark.sql.Row] = Array([10], [11], [12])

coalesce

The coalesce method reduces the number of partitions in a DataFrame. Here’s how to consolidate the data in two partitions:
val numbersDf2 = numbersDf.coalesce(2)

We can verify coalesce has created a new DataFrame with only two partitions:
numbersDf2.rdd.partitions.size
res25: Int = 2

numbersDf2 will be written out to disc as two text files:
 numbersDf2.write.csv("/Users/p.kumar.bishwal/Documents/python/codeNdata/output/numbers2")

now you can see 2 files are created in the above folder 

scala> spark.read.format("csv").load("/Users/p.kumar.bishwal/Documents/python/codeNdata/output/numbers2/part-00000.csv").collect()
res27: Array[org.apache.spark.sql.Row] = Array([1], [2], [3], [4], [5], [6])

scala> spark.read.format("csv").load("/Users/p.kumar.bishwal/Documents/python/codeNdata/output/numbers2/part-00001.csv").collect()
res28: Array[org.apache.spark.sql.Row] = Array([7], [8], [9], [10], [11], [12])

The coalesce algorithm moved the data from Partition B to Partition A and moved the data from Partition D to Partition C. 
The data in Partition A and Partition C does not move with the coalesce algorithm. 
This algorithm is fast in certain situations because it minimizes data movement.


Increasing partitions
======================
You can try to increase the number of partitions with coalesce, but it won’t work!
scala> val numbersDf3 = numbersDf.coalesce(6)
numbersDf3: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [number: int]

scala> numbersDf3.rdd.partitions.size 
res29: Int = 4

numbersDf3 keeps four partitions even though we attemped to create 6 partitions with coalesce(6).

The coalesce algorithm changes the number of nodes by moving data from some partitions to existing partitions. 
This algorithm obviously cannot increase the number of partitions.

 numbersDf3.write.csv("/Users/p.kumar.bishwal/Documents/python/codeNdata/output/numbers3")
 
scala> spark.read.format("csv").load("/Users/p.kumar.bishwal/Documents/python/codeNdata/output/numbers3/part-00003.csv").collect()
res31: Array[org.apache.spark.sql.Row] = Array([10], [11], [12])


repartition
============
The repartition method can be used to either increase or decrease the number of partitions in a DataFrame.

Let’s create a homerDf from the numbersDf with two partitions.
scala> val homerDf = numbersDf.repartition(2)
homerDf: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [number: int]

scala> homerDf.rdd.partitions.size 
res35: Int = 2

 homerDf.write.csv("/Users/p.kumar.bishwal/Documents/python/codeNdata/output/homerDf")
this will create 2 partitions 

spark.read.format("csv").load("/Users/p.kumar.bishwal/Documents/python/codeNdata/output/homerDf/part-00001.csv").collect()
res38: Array[org.apache.spark.sql.Row] = Array([2], [5], [8], [11])

spark.read.format("csv").load("/Users/p.kumar.bishwal/Documents/python/codeNdata/output/homerDf/part-00000.csv").collect()
res39: Array[org.apache.spark.sql.Row] = Array([1], [3], [4], [6], [7], [9], [10], [12])

The repartition algorithm does a full data shuffle and equally distributes the data among the partitions. 
It does not attempt to minimize data movement like the coalesce algorithm.

Increasing partitions
=======================

The repartition method can be used to increase the number of partitions as well.
scala> val bartDf = numbersDf.repartition(6)
bartDf: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [number: int]

scala> bartDf.rdd.partitions.size
res40: Int = 6

Here’s how the data is split up amongst the partitions in the bartDf.
 bartDf.write.csv("/Users/p.kumar.bishwal/Documents/python/codeNdata/output/bartDf")
here you can see 6 partitons being created 

spark.read.format("csv").load("/Users/p.kumar.bishwal/Documents/python/codeNdata/output/bartDf/part-00005.csv").collect()
res47: Array[org.apache.spark.sql.Row] = Array([5], [7], [12])

The repartition method does a full shuffle of the data, so the number of partitions can be increased.

Differences between coalesce and repartition
==============================================

The repartition algorithm does a full shuffle of the data and creates equal sized partitions of data. 
coalesce combines existing partitions to avoid a full shuffle.

repartition by column
===================== 

Let’s use the following data to examine how a DataFrame can be repartitioned by a particular column.

val people = List((10, "blue"),(13, "red"),(15, "blue"),(99, "red"),(67, "blue"))

val peopleDf = people.toDF("age", "color")
peopleDf: org.apache.spark.sql.DataFrame = [age: int, color: string]

Let’s repartition the DataFrame by the color column:

val colorDf =peopleDf.repartition($"color")

When partitioning by a column, Spark will create a minimum of 200 partitions by default. 
This example will have two partitions with data and 198 empty partitions.

 colorDf.write.csv("/Users/p.kumar.bishwal/Documents/python/codeNdata/output/colorDf")
now you can see 200 partitions by default and most of them don't have data in it 

The colorDf contains different partitions for each color and is optimized for extracts by color.
Partitioning by a column is similar to indexing a column in a relational database.


scala> colorDf.explain
== Physical Plan ==
Exchange hashpartitioning(color#339, 200)
+- LocalTableScan [age#338, color#339]

******************************
this is not working check in home mac 
lets set the partitions to 5 now and again run the above command with it 
sqlContext.sql("set spark.sql.shuffle.partitions=5");

colorDf.write.csv("/Users/p.kumar.bishwal/Documents/python/codeNdata/output/colorDf1")

******************************

In general, you can determine the number of partitions by multiplying the number of CPUs in the cluster by 2, 3, or 4

number_of_partitions = number_of_cpus * 4

If you’re writing the data out to a file system, you can choose a partition size that will create reasonable sized files (100MB). 
Spark will optimize the number of partitions based on the number of clusters when the data is read.

When filtering large DataFrames into smaller ones, you should almost always repartition the data.

Difference between coalesce and repartition

coalesce uses existing partitions to minimize the amount of data that's shuffled. 
repartition creates new partitions and does a full shuffle. 
coalesce results in partitions with different amounts of data (sometimes partitions that have much different sizes) and 
repartition results in roughly equal sized partitions.

Is coalesce or repartition faster?

coalesce may run faster than repartition, but unequal sized partitions are generally slower to work with than equal sized partitions. 
You'll usually need to repartition datasets after filtering a large data set. 
I've found repartition to be faster overall because Spark is built to work with equal sized partitions.
